Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (2, 4), destination = (5, 5), deadline = 20
RoutePlanner.route_to(): destination = (5, 5)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 3, # of penalties: 4
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 3, # of penalties: 6
Net reward: 2, # of penalties: 7
Net reward: 2, # of penalties: 8
Net reward: 1, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: -1, # of penalties: 11
Net reward: -1, # of penalties: 11
Net reward: -1, # of penalties: 11
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (7, 4), destination = (2, 3), deadline = 30
RoutePlanner.route_to(): destination = (2, 3)
Net reward: 0, # of penalties: 0
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 1, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 2, # of penalties: 5
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 2, # of penalties: 7
Net reward: 4, # of penalties: 7
Net reward: 4, # of penalties: 7
Net reward: 3, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 3, # of penalties: 9
Net reward: 5, # of penalties: 9
Net reward: 5, # of penalties: 9
Net reward: 4, # of penalties: 10
Net reward: 4, # of penalties: 11
Net reward: 3, # of penalties: 12
Net reward: 3, # of penalties: 12
Net reward: 5, # of penalties: 12
Net reward: 4, # of penalties: 13
Net reward: 3, # of penalties: 14
Net reward: 2, # of penalties: 15
Net reward: 1, # of penalties: 16
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (5, 1), destination = (7, 4), deadline = 25
RoutePlanner.route_to(): destination = (7, 4)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 2, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 3, # of penalties: 3
Net reward: 5, # of penalties: 3
Net reward: 5, # of penalties: 4
Net reward: 7, # of penalties: 4
Net reward: 6, # of penalties: 5
Net reward: 5, # of penalties: 6
Net reward: 5, # of penalties: 7
Net reward: 7, # of penalties: 7
Net reward: 6, # of penalties: 8
Net reward: 6, # of penalties: 9
Net reward: 8, # of penalties: 9
Net reward: 7, # of penalties: 10
Net reward: 7, # of penalties: 11
Net reward: 7, # of penalties: 11
Net reward: 7, # of penalties: 11
Net reward: 6, # of penalties: 12
Net reward: 5, # of penalties: 13
Net reward: 4, # of penalties: 14
Net reward: 4, # of penalties: 15
Net reward: 6, # of penalties: 15
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (6, 6), destination = (1, 6), deadline = 25
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 2, # of penalties: 2
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 1, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 1, # of penalties: 7
Net reward: 1, # of penalties: 7
Net reward: 1, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 2, # of penalties: 9
Net reward: 2, # of penalties: 9
Net reward: 1, # of penalties: 10
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (1, 1), destination = (5, 3), deadline = 30
RoutePlanner.route_to(): destination = (5, 3)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: -3, # of penalties: 3
Net reward: -3, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -1, # of penalties: 4
Net reward: -2, # of penalties: 5
Net reward: -2, # of penalties: 5
Net reward: -3, # of penalties: 6
Net reward: -4, # of penalties: 7
Net reward: -4, # of penalties: 7
Net reward: -2, # of penalties: 7
Net reward: -2, # of penalties: 8
Net reward: 0, # of penalties: 8
Net reward: 1, # of penalties: 8
Net reward: 1, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: -1, # of penalties: 11
Net reward: -2, # of penalties: 12
Net reward: -2, # of penalties: 12
Net reward: -2, # of penalties: 13
Net reward: -3, # of penalties: 14
Net reward: -3, # of penalties: 14
Net reward: -3, # of penalties: 14
Net reward: -1, # of penalties: 14
Net reward: -1, # of penalties: 15
Net reward: 0, # of penalties: 15
Net reward: 0, # of penalties: 15
Net reward: 0, # of penalties: 16
Net reward: -1, # of penalties: 17
Net reward: -1, # of penalties: 17
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 6), deadline = 45
RoutePlanner.route_to(): destination = (3, 6)
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -3, # of penalties: 5
Net reward: -4, # of penalties: 6
Net reward: -4, # of penalties: 6
Net reward: -5, # of penalties: 7
Net reward: -6, # of penalties: 8
Net reward: -4, # of penalties: 8
Net reward: -4, # of penalties: 8
Net reward: -4, # of penalties: 9
Net reward: -4, # of penalties: 9
Net reward: -5, # of penalties: 10
Net reward: -3, # of penalties: 10
Net reward: -3, # of penalties: 10
Net reward: -1, # of penalties: 10
Net reward: -2, # of penalties: 11
Net reward: -2, # of penalties: 12
Environment.act(): Primary agent has reached destination!
Net reward: 9, # of penalties: 12
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (1, 3), destination = (7, 5), deadline = 40
RoutePlanner.route_to(): destination = (7, 5)
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -2, # of penalties: 4
Net reward: -3, # of penalties: 5
Net reward: -4, # of penalties: 6
Net reward: -4, # of penalties: 7
Net reward: -5, # of penalties: 8
Net reward: -6, # of penalties: 9
Net reward: -6, # of penalties: 9
Net reward: -6, # of penalties: 9
Net reward: -4, # of penalties: 9
Net reward: -5, # of penalties: 10
Net reward: -6, # of penalties: 11
Net reward: -6, # of penalties: 12
Net reward: -4, # of penalties: 12
Net reward: -4, # of penalties: 12
Net reward: -5, # of penalties: 13
Environment.act(): Primary agent has reached destination!
Net reward: 6, # of penalties: 13
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (3, 5), destination = (6, 6), deadline = 20
RoutePlanner.route_to(): destination = (6, 6)
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -1, # of penalties: 4
Net reward: -1, # of penalties: 4
Net reward: -2, # of penalties: 5
Net reward: -3, # of penalties: 6
Net reward: -3, # of penalties: 6
Net reward: -3, # of penalties: 7
Net reward: -4, # of penalties: 8
Net reward: -5, # of penalties: 9
Net reward: -5, # of penalties: 9
Net reward: -3, # of penalties: 9
Net reward: -1, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: 0, # of penalties: 10
Net reward: 0, # of penalties: 10
Net reward: 1, # of penalties: 10
Net reward: 1, # of penalties: 10
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (1, 3), destination = (8, 1), deadline = 45
RoutePlanner.route_to(): destination = (8, 1)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: -1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 6
Net reward: -1, # of penalties: 7
Net reward: -2, # of penalties: 8
Net reward: -2, # of penalties: 8
Net reward: -3, # of penalties: 9
Net reward: -3, # of penalties: 9
Net reward: -1, # of penalties: 9
Net reward: 1, # of penalties: 9
Net reward: 1, # of penalties: 9
Net reward: 3, # of penalties: 9
Net reward: 3, # of penalties: 9
Net reward: 2, # of penalties: 10
Net reward: 1, # of penalties: 11
Net reward: 0, # of penalties: 12
Net reward: 0, # of penalties: 13
Net reward: -1, # of penalties: 14
Net reward: -2, # of penalties: 15
Net reward: -3, # of penalties: 16
Net reward: -1, # of penalties: 16
Net reward: -1, # of penalties: 17
Net reward: 0, # of penalties: 17
Net reward: 2, # of penalties: 17
Net reward: 2, # of penalties: 18
Net reward: 1, # of penalties: 19
Net reward: 3, # of penalties: 19
Net reward: 2, # of penalties: 20
Net reward: 2, # of penalties: 21
Net reward: 2, # of penalties: 21
Net reward: 1, # of penalties: 22
Net reward: 1, # of penalties: 22
Net reward: 1, # of penalties: 23
Net reward: 0, # of penalties: 24
Net reward: 0, # of penalties: 25
Net reward: 0, # of penalties: 25
Net reward: 0, # of penalties: 25
Net reward: -1, # of penalties: 26
Net reward: -1, # of penalties: 27
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (7, 3), destination = (1, 5), deadline = 40
RoutePlanner.route_to(): destination = (1, 5)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: -3, # of penalties: 3
Net reward: -1, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 0, # of penalties: 4
Net reward: 0, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 6
Net reward: 0, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 8
Net reward: -1, # of penalties: 9
Net reward: -1, # of penalties: 10
Net reward: 0, # of penalties: 10
Net reward: 0, # of penalties: 11
Net reward: -1, # of penalties: 12
Net reward: -1, # of penalties: 13
Net reward: -2, # of penalties: 14
Net reward: -3, # of penalties: 15
Net reward: -4, # of penalties: 16
Net reward: -5, # of penalties: 17
Net reward: -5, # of penalties: 17
Net reward: -3, # of penalties: 17
Net reward: -1, # of penalties: 17
Net reward: 1, # of penalties: 17
Net reward: 0, # of penalties: 18
Net reward: -1, # of penalties: 19
Net reward: -1, # of penalties: 20
Net reward: -2, # of penalties: 21
Net reward: -2, # of penalties: 21
Net reward: -3, # of penalties: 22
Net reward: -4, # of penalties: 23
Net reward: -4, # of penalties: 23
Net reward: -4, # of penalties: 23
Net reward: -4, # of penalties: 24
Net reward: -5, # of penalties: 25
Net reward: -5, # of penalties: 25
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (7, 3), destination = (1, 6), deadline = 45
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 1, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 3, # of penalties: 4
Net reward: 3, # of penalties: 4
Net reward: 2, # of penalties: 5
Net reward: 4, # of penalties: 5
Net reward: 4, # of penalties: 6
Net reward: 4, # of penalties: 6
Net reward: 3, # of penalties: 7
Net reward: 3, # of penalties: 8
Net reward: 2, # of penalties: 9
Net reward: 4, # of penalties: 9
Net reward: 4, # of penalties: 9
Net reward: 4, # of penalties: 9
Net reward: 3, # of penalties: 10
Net reward: 2, # of penalties: 11
Net reward: 1, # of penalties: 12
Net reward: 0, # of penalties: 13
Net reward: 0, # of penalties: 13
Net reward: 0, # of penalties: 13
Net reward: 0, # of penalties: 13
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 15
Net reward: 0, # of penalties: 15
Net reward: -1, # of penalties: 16
Net reward: -1, # of penalties: 16
Net reward: -1, # of penalties: 17
Net reward: -2, # of penalties: 18
Net reward: -3, # of penalties: 19
Net reward: -1, # of penalties: 19
Net reward: -1, # of penalties: 19
Net reward: 1, # of penalties: 19
Net reward: 1, # of penalties: 19
Net reward: 1, # of penalties: 19
Net reward: 0, # of penalties: 20
Net reward: 0, # of penalties: 21
Net reward: 0, # of penalties: 21
Net reward: 0, # of penalties: 22
Net reward: 0, # of penalties: 22
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (8, 1), destination = (5, 5), deadline = 35
RoutePlanner.route_to(): destination = (5, 5)
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -3, # of penalties: 5
Net reward: -4, # of penalties: 6
Net reward: -5, # of penalties: 7
Net reward: -6, # of penalties: 8
Net reward: -4, # of penalties: 8
Net reward: -5, # of penalties: 9
Net reward: -6, # of penalties: 10
Net reward: -6, # of penalties: 11
Net reward: -6, # of penalties: 11
Net reward: -7, # of penalties: 12
Net reward: -5, # of penalties: 12
Net reward: -3, # of penalties: 12
Net reward: -3, # of penalties: 12
Net reward: -3, # of penalties: 13
Net reward: -4, # of penalties: 14
Net reward: -4, # of penalties: 14
Net reward: -5, # of penalties: 15
Net reward: -5, # of penalties: 15
Net reward: -5, # of penalties: 16
Net reward: -6, # of penalties: 17
Net reward: -7, # of penalties: 18
Net reward: -5, # of penalties: 18
Net reward: -5, # of penalties: 19
Net reward: -6, # of penalties: 20
Net reward: -6, # of penalties: 20
Net reward: -7, # of penalties: 21
Net reward: -7, # of penalties: 21
Net reward: -8, # of penalties: 22
Net reward: -8, # of penalties: 23
Net reward: -6, # of penalties: 23
Net reward: -7, # of penalties: 24
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (8, 5), destination = (6, 3), deadline = 20
RoutePlanner.route_to(): destination = (6, 3)
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 3
Net reward: -2, # of penalties: 4
Net reward: -3, # of penalties: 5
Net reward: -3, # of penalties: 6
Net reward: -4, # of penalties: 7
Net reward: -5, # of penalties: 8
Net reward: -6, # of penalties: 9
Net reward: -4, # of penalties: 9
Net reward: -4, # of penalties: 10
Net reward: -4, # of penalties: 10
Net reward: -2, # of penalties: 10
Net reward: -3, # of penalties: 11
Net reward: -4, # of penalties: 12
Net reward: -4, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -3, # of penalties: 14
Net reward: -4, # of penalties: 15
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (8, 5), destination = (4, 5), deadline = 20
RoutePlanner.route_to(): destination = (4, 5)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 3, # of penalties: 3
Net reward: 2, # of penalties: 4
Net reward: 1, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 2, # of penalties: 6
Net reward: 2, # of penalties: 6
Net reward: 1, # of penalties: 7
Net reward: 1, # of penalties: 8
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: 1, # of penalties: 10
Net reward: 1, # of penalties: 10
Net reward: 1, # of penalties: 11
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (1, 5), destination = (4, 1), deadline = 35
RoutePlanner.route_to(): destination = (4, 1)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 3, # of penalties: 3
Net reward: 2, # of penalties: 4
Net reward: 1, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 3, # of penalties: 5
Net reward: 2, # of penalties: 6
Net reward: 1, # of penalties: 7
Net reward: 3, # of penalties: 7
Net reward: 3, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 5, # of penalties: 8
Net reward: 7, # of penalties: 8
Net reward: 6, # of penalties: 9
Net reward: 6, # of penalties: 10
Net reward: 8, # of penalties: 10
Environment.act(): Primary agent has reached destination!
Net reward: 20, # of penalties: 10
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (6, 1), destination = (7, 4), deadline = 20
RoutePlanner.route_to(): destination = (7, 4)
Net reward: 0, # of penalties: 0
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 4, # of penalties: 3
Net reward: 3, # of penalties: 4
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: 0, # of penalties: 9
Net reward: -1, # of penalties: 10
Net reward: -2, # of penalties: 11
Net reward: -3, # of penalties: 12
Net reward: -1, # of penalties: 12
Net reward: -2, # of penalties: 13
Net reward: -3, # of penalties: 14
Net reward: -4, # of penalties: 15
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (3, 1), destination = (1, 6), deadline = 35
RoutePlanner.route_to(): destination = (1, 6)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: -2, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: -1, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 0, # of penalties: 4
Net reward: 0, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: -1, # of penalties: 8
Net reward: 1, # of penalties: 8
Net reward: 0, # of penalties: 9
Net reward: 2, # of penalties: 9
Net reward: 1, # of penalties: 10
Environment.act(): Primary agent has reached destination!
Net reward: 11, # of penalties: 10
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (3, 5), destination = (4, 2), deadline = 20
RoutePlanner.route_to(): destination = (4, 2)
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 5, # of penalties: 2
Net reward: 4, # of penalties: 3
Net reward: 3, # of penalties: 4
Net reward: 2, # of penalties: 5
Net reward: 1, # of penalties: 6
Net reward: 3, # of penalties: 6
Net reward: 3, # of penalties: 6
Net reward: 3, # of penalties: 7
Net reward: 3, # of penalties: 7
Net reward: 3, # of penalties: 7
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (5, 3), destination = (2, 5), deadline = 25
RoutePlanner.route_to(): destination = (2, 5)
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 3, # of penalties: 2
Environment.act(): Primary agent has reached destination!
Net reward: 15, # of penalties: 2
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (4, 4), destination = (7, 6), deadline = 25
RoutePlanner.route_to(): destination = (7, 6)
Net reward: 0, # of penalties: 0
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: -1, # of penalties: 4
Net reward: 1, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 1, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: -1, # of penalties: 9
Net reward: -2, # of penalties: 10
Net reward: 0, # of penalties: 10
Net reward: 0, # of penalties: 11
Net reward: -1, # of penalties: 12
Net reward: -1, # of penalties: 13
Net reward: -2, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: -1, # of penalties: 15
Net reward: 1, # of penalties: 15
Net reward: 3, # of penalties: 15
Net reward: 3, # of penalties: 15
Net reward: 3, # of penalties: 15
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (6, 4), destination = (1, 4), deadline = 25
RoutePlanner.route_to(): destination = (1, 4)
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 0, # of penalties: 3
Net reward: -1, # of penalties: 4
Net reward: -2, # of penalties: 5
Net reward: -2, # of penalties: 6
Net reward: 0, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: -1, # of penalties: 9
Net reward: -1, # of penalties: 9
Net reward: -1, # of penalties: 10
Net reward: -2, # of penalties: 11
Net reward: -2, # of penalties: 11
Net reward: -2, # of penalties: 11
Net reward: -3, # of penalties: 12
Net reward: -3, # of penalties: 13
Net reward: -1, # of penalties: 13
Net reward: -2, # of penalties: 14
Net reward: -2, # of penalties: 14
Net reward: -2, # of penalties: 14
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (8, 5), destination = (1, 5), deadline = 35
RoutePlanner.route_to(): destination = (1, 5)
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -4, # of penalties: 5
Environment.act(): Primary agent has reached destination!
Net reward: 8, # of penalties: 5
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (7, 5), destination = (4, 4), deadline = 20
RoutePlanner.route_to(): destination = (4, 4)
Net reward: -1, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -2, # of penalties: 3
Net reward: -2, # of penalties: 3
Net reward: -2, # of penalties: 4
Net reward: -3, # of penalties: 5
Net reward: -1, # of penalties: 5
Net reward: -1, # of penalties: 6
Net reward: 0, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: 1, # of penalties: 8
Net reward: 1, # of penalties: 8
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: 2, # of penalties: 10
Net reward: 1, # of penalties: 11
Net reward: 1, # of penalties: 11
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (5, 2), destination = (1, 6), deadline = 40
RoutePlanner.route_to(): destination = (1, 6)
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: -1, # of penalties: 4
Net reward: 0, # of penalties: 4
Net reward: 2, # of penalties: 4
Net reward: 4, # of penalties: 4
Net reward: 3, # of penalties: 5
Net reward: 3, # of penalties: 6
Net reward: 3, # of penalties: 6
Net reward: 2, # of penalties: 7
Net reward: 2, # of penalties: 7
Net reward: 2, # of penalties: 8
Net reward: 2, # of penalties: 8
Net reward: 1, # of penalties: 9
Net reward: 0, # of penalties: 10
Net reward: -1, # of penalties: 11
Net reward: -1, # of penalties: 12
Net reward: -1, # of penalties: 12
Net reward: -2, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -3, # of penalties: 14
Net reward: -1, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 14
Net reward: 0, # of penalties: 15
Net reward: 0, # of penalties: 16
Net reward: 0, # of penalties: 16
Net reward: 1, # of penalties: 16
Net reward: 0, # of penalties: 17
Net reward: 2, # of penalties: 17
Net reward: 4, # of penalties: 17
Net reward: 6, # of penalties: 17
Net reward: 5, # of penalties: 18
Net reward: 4, # of penalties: 19
Net reward: 6, # of penalties: 19
Net reward: 6, # of penalties: 20
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (8, 3), destination = (6, 1), deadline = 20
RoutePlanner.route_to(): destination = (6, 1)
Net reward: -1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 1, # of penalties: 4
Net reward: 1, # of penalties: 5
Net reward: 0, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 8
Net reward: -1, # of penalties: 9
Net reward: -2, # of penalties: 10
Net reward: -2, # of penalties: 10
Net reward: -3, # of penalties: 11
Net reward: -4, # of penalties: 12
Net reward: -4, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: 0, # of penalties: 13
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (8, 1), destination = (1, 2), deadline = 40
RoutePlanner.route_to(): destination = (1, 2)
Net reward: 0, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 11, # of penalties: 1
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 6), deadline = 35
RoutePlanner.route_to(): destination = (8, 6)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 3
Net reward: 1, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 5
Net reward: 0, # of penalties: 5
Net reward: -1, # of penalties: 6
Net reward: -2, # of penalties: 7
Net reward: -3, # of penalties: 8
Net reward: -3, # of penalties: 9
Net reward: -4, # of penalties: 10
Net reward: -2, # of penalties: 10
Net reward: -3, # of penalties: 11
Net reward: -1, # of penalties: 11
Net reward: -1, # of penalties: 11
Net reward: -1, # of penalties: 12
Net reward: -1, # of penalties: 12
Net reward: -1, # of penalties: 12
Net reward: -2, # of penalties: 13
Net reward: 0, # of penalties: 13
Net reward: -1, # of penalties: 14
Net reward: -2, # of penalties: 15
Net reward: -3, # of penalties: 16
Net reward: -3, # of penalties: 17
Net reward: -4, # of penalties: 18
Net reward: -2, # of penalties: 18
Net reward: -2, # of penalties: 18
Net reward: -3, # of penalties: 19
Net reward: -3, # of penalties: 20
Net reward: -1, # of penalties: 20
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (8, 4), destination = (1, 2), deadline = 45
RoutePlanner.route_to(): destination = (1, 2)
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 0, # of penalties: 3
Net reward: 0, # of penalties: 4
Net reward: -1, # of penalties: 5
Net reward: -2, # of penalties: 6
Net reward: -3, # of penalties: 7
Net reward: -4, # of penalties: 8
Net reward: -4, # of penalties: 9
Net reward: -2, # of penalties: 9
Net reward: 0, # of penalties: 9
Net reward: -1, # of penalties: 10
Net reward: -2, # of penalties: 11
Net reward: -2, # of penalties: 11
Net reward: 0, # of penalties: 11
Net reward: 0, # of penalties: 11
Net reward: -1, # of penalties: 12
Net reward: -2, # of penalties: 13
Net reward: -2, # of penalties: 13
Net reward: -3, # of penalties: 14
Net reward: -4, # of penalties: 15
Net reward: -4, # of penalties: 15
Net reward: -5, # of penalties: 16
Net reward: -5, # of penalties: 16
Net reward: -3, # of penalties: 16
Net reward: -4, # of penalties: 17
Net reward: -4, # of penalties: 17
Net reward: -4, # of penalties: 18
Net reward: -5, # of penalties: 19
Net reward: -6, # of penalties: 20
Net reward: -6, # of penalties: 20
Net reward: -4, # of penalties: 20
Net reward: -2, # of penalties: 20
Net reward: -2, # of penalties: 20
Net reward: 0, # of penalties: 20
Net reward: 0, # of penalties: 20
Net reward: 2, # of penalties: 20
Net reward: 2, # of penalties: 20
Net reward: 2, # of penalties: 20
Net reward: 2, # of penalties: 20
Net reward: 1, # of penalties: 21
Net reward: 1, # of penalties: 21
Net reward: 1, # of penalties: 22
Net reward: 1, # of penalties: 22
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (6, 2), destination = (3, 4), deadline = 25
RoutePlanner.route_to(): destination = (3, 4)
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 2
Net reward: 1, # of penalties: 2
Net reward: 3, # of penalties: 2
Net reward: 2, # of penalties: 3
Net reward: 2, # of penalties: 3
Net reward: 2, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 6, # of penalties: 3
Net reward: 5, # of penalties: 4
Net reward: 5, # of penalties: 4
Environment.act(): Primary agent has reached destination!
Net reward: 17, # of penalties: 4
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (8, 6), destination = (2, 2), deadline = 50
RoutePlanner.route_to(): destination = (2, 2)
Net reward: -1, # of penalties: 1
Net reward: -2, # of penalties: 2
Net reward: -3, # of penalties: 3
Net reward: -3, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -1, # of penalties: 4
Net reward: 0, # of penalties: 4
Net reward: 0, # of penalties: 5
Net reward: -1, # of penalties: 6
Net reward: -1, # of penalties: 6
Net reward: -1, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 1, # of penalties: 6
Net reward: 0, # of penalties: 7
Net reward: 0, # of penalties: 7
Net reward: 2, # of penalties: 7
Net reward: 1, # of penalties: 8
Net reward: 1, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 3, # of penalties: 8
Net reward: 2, # of penalties: 9
Net reward: 1, # of penalties: 10
Net reward: 3, # of penalties: 10
Net reward: 5, # of penalties: 10
Net reward: 5, # of penalties: 11
Net reward: 7, # of penalties: 11
Net reward: 6, # of penalties: 12
Net reward: 5, # of penalties: 13
Net reward: 7, # of penalties: 13
Net reward: 9, # of penalties: 13
Net reward: 9, # of penalties: 13
Net reward: 9, # of penalties: 13
Net reward: 11, # of penalties: 13
Net reward: 10, # of penalties: 14
Net reward: 10, # of penalties: 14
Net reward: 10, # of penalties: 14
Net reward: 9, # of penalties: 15
Net reward: 9, # of penalties: 15
Net reward: 9, # of penalties: 16
Net reward: 11, # of penalties: 16
Net reward: 11, # of penalties: 16
Net reward: 10, # of penalties: 17
Net reward: 9, # of penalties: 18
Net reward: 8, # of penalties: 19
Net reward: 8, # of penalties: 20
Net reward: 10, # of penalties: 20
Net reward: 12, # of penalties: 20
Net reward: 11, # of penalties: 21
Net reward: 11, # of penalties: 21
Net reward: 11, # of penalties: 21
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (8, 4), destination = (2, 6), deadline = 40
RoutePlanner.route_to(): destination = (2, 6)
Net reward: 0, # of penalties: 1
Net reward: 0, # of penalties: 1
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: -1, # of penalties: 2
Net reward: -2, # of penalties: 3
Net reward: -2, # of penalties: 3
Net reward: -3, # of penalties: 4
Net reward: -4, # of penalties: 5
Net reward: -2, # of penalties: 5
Environment.act(): Primary agent has reached destination!
Net reward: 10, # of penalties: 5
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (7, 3), destination = (2, 3), deadline = 25
RoutePlanner.route_to(): destination = (2, 3)
Net reward: 0, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 0, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 6, # of penalties: 3
Net reward: 8, # of penalties: 3
Net reward: 8, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 10, # of penalties: 3
Net reward: 9, # of penalties: 4
Net reward: 8, # of penalties: 5
Net reward: 8, # of penalties: 5
Net reward: 8, # of penalties: 5
Net reward: 8, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 10, # of penalties: 6
Net reward: 9, # of penalties: 7
Net reward: 11, # of penalties: 7
Net reward: 11, # of penalties: 7
Net reward: 13, # of penalties: 7
Net reward: 12, # of penalties: 8
Net reward: 14, # of penalties: 8
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (3, 4), destination = (8, 6), deadline = 35
RoutePlanner.route_to(): destination = (8, 6)
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 13, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 25, # of penalties: 1
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (7, 2), destination = (1, 4), deadline = 40
RoutePlanner.route_to(): destination = (1, 4)
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 2
Net reward: 0, # of penalties: 3
Net reward: 2, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 3
Net reward: 4, # of penalties: 4
Net reward: 6, # of penalties: 4
Net reward: 6, # of penalties: 4
Net reward: 6, # of penalties: 4
Net reward: 8, # of penalties: 4
Net reward: 10, # of penalties: 4
Net reward: 10, # of penalties: 4
Net reward: 10, # of penalties: 4
Net reward: 12, # of penalties: 4
Net reward: 11, # of penalties: 5
Net reward: 10, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 12, # of penalties: 6
Net reward: 12, # of penalties: 6
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 6
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (2, 3), destination = (7, 3), deadline = 25
RoutePlanner.route_to(): destination = (7, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 8, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 8, # of penalties: 2
Environment.act(): Primary agent has reached destination!
Net reward: 20, # of penalties: 2
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (6, 4), destination = (7, 1), deadline = 20
RoutePlanner.route_to(): destination = (7, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (2, 6), destination = (2, 1), deadline = 25
RoutePlanner.route_to(): destination = (2, 1)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 20, # of penalties: 0
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (5, 4), destination = (2, 1), deadline = 30
RoutePlanner.route_to(): destination = (2, 1)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 11, # of penalties: 1
Net reward: 11, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 23, # of penalties: 1
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (4, 1), destination = (6, 3), deadline = 20
RoutePlanner.route_to(): destination = (6, 3)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 19, # of penalties: 1
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (7, 3), destination = (1, 3), deadline = 30
RoutePlanner.route_to(): destination = (1, 3)
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Net reward: 9, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 21, # of penalties: 1
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (7, 2), destination = (3, 6), deadline = 40
RoutePlanner.route_to(): destination = (3, 6)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 2, # of penalties: 2
Net reward: 2, # of penalties: 2
Net reward: 4, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 6, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 8, # of penalties: 2
Net reward: 10, # of penalties: 2
Net reward: 12, # of penalties: 2
Environment.act(): Primary agent has reached destination!
Net reward: 24, # of penalties: 2
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (5, 6), destination = (5, 2), deadline = 20
RoutePlanner.route_to(): destination = (5, 2)
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 0, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 19, # of penalties: 1
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (3, 3), destination = (4, 6), deadline = 20
RoutePlanner.route_to(): destination = (4, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (6, 1), destination = (5, 4), deadline = 20
RoutePlanner.route_to(): destination = (5, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (6, 6), destination = (6, 2), deadline = 20
RoutePlanner.route_to(): destination = (6, 2)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 19, # of penalties: 1
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (7, 2), destination = (5, 6), deadline = 30
RoutePlanner.route_to(): destination = (5, 6)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 10, # of penalties: 0
Net reward: 9, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 21, # of penalties: 1
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (6, 1), destination = (3, 2), deadline = 20
RoutePlanner.route_to(): destination = (3, 2)
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (6, 1), destination = (2, 3), deadline = 30
RoutePlanner.route_to(): destination = (2, 3)
Net reward: -1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 1, # of penalties: 1
Net reward: 3, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 5, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 7, # of penalties: 1
Net reward: 9, # of penalties: 1
Environment.act(): Primary agent has reached destination!
Net reward: 21, # of penalties: 1
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (2, 4), destination = (6, 4), deadline = 20
RoutePlanner.route_to(): destination = (6, 4)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Net reward: 10, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 22, # of penalties: 0
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (6, 2), destination = (5, 5), deadline = 20
RoutePlanner.route_to(): destination = (5, 5)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 18, # of penalties: 0
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (4, 1), destination = (1, 3), deadline = 25
RoutePlanner.route_to(): destination = (1, 3)
Net reward: 2, # of penalties: 0
Net reward: 4, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 6, # of penalties: 0
Net reward: 8, # of penalties: 0
Environment.act(): Primary agent has reached destination!
Net reward: 20, # of penalties: 0
